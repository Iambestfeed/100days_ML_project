{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class DecisionTreeEntropy:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Compute the entropy for a given set of class labels.\n",
    "        \n",
    "        Parameters:\n",
    "            y (np.array): Array of class labels.\n",
    "        \n",
    "        Returns:\n",
    "            float: Entropy score.\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-9))\n",
    "    \n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Determines the best feature and threshold for splitting the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.array): Feature matrix.\n",
    "            y (np.array): Target labels.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (feature index, threshold) that results in the lowest weighted entropy.\n",
    "        \"\"\"\n",
    "        best_entropy = float('inf')\n",
    "        best_split = None\n",
    "        m, n = X.shape\n",
    "        \n",
    "        for feature_idx in range(n):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature_idx] <= threshold\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if sum(left_indices) < self.min_samples_split or sum(right_indices) < self.min_samples_split:\n",
    "                    continue\n",
    "                \n",
    "                left_entropy = self.entropy(y[left_indices])\n",
    "                right_entropy = self.entropy(y[right_indices])\n",
    "                weighted_entropy = (sum(left_indices) * left_entropy + sum(right_indices) * right_entropy) / m\n",
    "                \n",
    "                if weighted_entropy < best_entropy:\n",
    "                    best_entropy = weighted_entropy\n",
    "                    best_split = (feature_idx, threshold)\n",
    "        \n",
    "        return best_split\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Recursively builds the decision tree using the best feature splits.\n",
    "        \n",
    "        Stopping criteria:\n",
    "        - If all samples belong to the same class, return that class.\n",
    "        - If the maximum depth is reached, return the majority class.\n",
    "        - If no valid split is found, return the majority class.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.array): Feature matrix.\n",
    "            y (np.array): Target labels.\n",
    "            depth (int): Current depth of the tree.\n",
    "        \n",
    "        Returns:\n",
    "            dict or int: A dictionary representing the tree structure, or a class label for leaf nodes.\n",
    "        \"\"\"\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return np.bincount(y).argmax()\n",
    "        if self.max_depth and depth >= self.max_depth:\n",
    "            return np.bincount(y).argmax()\n",
    "        \n",
    "        split = self.best_split(X, y)\n",
    "        if split is None:\n",
    "            return np.bincount(y).argmax()\n",
    "        \n",
    "        feature_idx, threshold = split\n",
    "        left_indices = X[:, feature_idx] <= threshold\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        return {\n",
    "            'feature': feature_idx,\n",
    "            'threshold': threshold,\n",
    "            'left': self.build_tree(X[left_indices], y[left_indices], depth + 1),\n",
    "            'right': self.build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the decision tree classifier to the given dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.array): Feature matrix.\n",
    "            y (np.array): Target labels.\n",
    "        \"\"\"\n",
    "        self.tree = self.build_tree(X, y)\n",
    "    \n",
    "    def predict_sample(self, sample, node):\n",
    "        \"\"\"\n",
    "        Predicts the class label for a single sample using the trained tree.\n",
    "        \n",
    "        Parameters:\n",
    "            sample (np.array): A single data point.\n",
    "            node (dict or int): Current node in the decision tree.\n",
    "        \n",
    "        Returns:\n",
    "            int: Predicted class label.\n",
    "        \"\"\"\n",
    "        if isinstance(node, dict):\n",
    "            if sample[node['feature']] <= node['threshold']:\n",
    "                return self.predict_sample(sample, node['left'])\n",
    "            else:\n",
    "                return self.predict_sample(sample, node['right'])\n",
    "        return node\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class labels for a dataset using the trained tree.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.array): Feature matrix.\n",
    "        \n",
    "        Returns:\n",
    "            np.array: Predicted class labels.\n",
    "        \"\"\"\n",
    "        return np.array([self.predict_sample(sample, self.tree) for sample in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "    \n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "    \n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=242025\n",
    ")\n",
    "    \n",
    "# Train model\n",
    "model = DecisionTreeEntropy(\n",
    "    max_depth=5\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nTest accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 2,\n",
       " 'threshold': np.float64(-1.056039392054748),\n",
       " 'left': np.int64(0),\n",
       " 'right': {'feature': 2,\n",
       "  'threshold': np.float64(0.5354085615261401),\n",
       "  'left': {'feature': 0,\n",
       "   'threshold': np.float64(-1.1430169111851116),\n",
       "   'left': np.int64(1),\n",
       "   'right': np.int64(1)},\n",
       "  'right': {'feature': 3,\n",
       "   'threshold': np.float64(0.659038469346772),\n",
       "   'left': {'feature': 0,\n",
       "    'threshold': np.float64(0.5533332750260058),\n",
       "    'left': np.int64(2),\n",
       "    'right': np.int64(1)},\n",
       "   'right': np.int64(2)}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
