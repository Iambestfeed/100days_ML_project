# ğŸš€ 100-Day Machine Learning Architecture Challenge

**Dive deep into model architectures, from classic MLPs to cutting-edge Transformers, GANs, and Diffusion Models. Code-first approach with daily implementation tasks.**

## ğŸ“Œ Overview

A structured 100-day journey to **build and understand machine learning architectures** from scratch. No deployment/projects â€“ pure model intuition through code.

**Key Features**:
- ğŸ§  **Hands-On Implementation**: Code critical components daily (e.g., backprop, attention layers)
- ğŸ“ˆ **Phased Learning**: 5 phases covering Foundations â†’ Generative Models â†’ Transformers â†’ Optimization â†’ Debugging
- ğŸ›  **Framework Guidance**: NumPy for fundamentals, PyTorch/TensorFlow for complex architectures
- ğŸ”¥ **Modern Focus**: Diffusion models, Flash Attention, LoRA, and more

## ğŸ—“ Phase Breakdown

| Phase | Days | Focus | Key Topics |
|-------|------|-------|------------|
| 1ï¸âƒ£ **Foundations** | 1-20 | Classical Models & Neural Networks | Linear Regression, CNNs, MLPs, Data Augmentation |
| 2ï¸âƒ£ **Generative Models** | 21-40 | RNNs & Generative Architectures | LSTMs, VAEs, GANs, Diffusion Models |
| 3ï¸âƒ£ **Transformers** | 41-70 | Modern Architectures & Efficiency | Transformers, BERT, ViT, YOLO, LoRA |
| 4ï¸âƒ£ **Optimization** | 71-90 | Training & Speed Hacks | Mixed Precision, Gradient Checkpointing, Quantization |
| 5ï¸âƒ£ **Analysis** | 91-100 | Debugging & Interpretation | Attention Heatmaps, SHAP, Loss Landscapes |

## ğŸ› ï¸ Frameworks & Tools

- **Core**: `NumPy`, `PyTorch`, `TensorFlow`
- **NLP**: `Hugging Face Transformers`
- **Vision**: `OpenCV`, `TorchVision`
- **Analysis**: `Captum`, `SHAP`, `PyTorch Profiler`

## ğŸš€ Getting Started

1. **Clone Repo**:
```bash
git clone https://github.com/yourusername/100day-ml-architecture.git
cd 100day-ml-architecture
```

2. **Set Up Environment**:
```bash
conda create -n ml100 python=3.10
conda activate ml100
conda install --yes --file requirements.txt
```

3. **Daily Task Structure**:
- ğŸ“ `Day01_Linear_Regression`: Contains `numpy_implementation.ipynb`
- ğŸ“– **Goal**: Implement SGD from scratch

## ğŸŒŸ Key Adjustments from Traditional Curricula

| Focus Area | Our Approach | Why It Matters |
|------------|--------------|----------------|
| **Foundations** | Prioritized MLP/CNN implementations over clustering | Builds intuition for neural networks |
| **Generative Models** | Integrated diffusion models early | Covers modern SOTA approaches |
| **Efficiency** | Added LoRA, quantization, Flash Attention | Prepares for real-world deployment |

## ğŸ¤ Contribution

Contributions welcome! Open an issue or PR for:
- ğŸ› Bug fixes
- ğŸ“š New implementation examples
- ğŸ“Š Additional datasets/benchmarks

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

**By Day 100, you'll be able to**: 
- Implement any paper's architecture from scratch ğŸ› ï¸
- Optimize models for speed/memory without sacrificing accuracy âš¡
- Explain model decisions using modern interpretability tools ğŸ”

*Start coding your way to ML mastery today!* ğŸ”¥
